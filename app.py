import streamlit as st
import os
import PyPDF2
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

# Azure AI Search ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
search_endpoint = os.getenv("SEARCH_ENDPOINT")
search_key = os.getenv("SEARCH_KEY")
search_index = os.getenv("SEARCH_INDEX_NAME", "fileupload-civil-procedure-2024-judicial-precedent-data") # ë„¤ê°€ ë§Œë“  ì¸ë±ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€ê²½!

st.title("ğŸ¤– ë¯¼ì‚¬íŒë¡€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ë“œë ¤ìš”!")
st.caption("íŒë¡€ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜, íŒê²°ë¬¸ íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.")
with st.sidebar:
    st.header("ğŸ“„ íŒê²°ë¬¸ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë˜ê·¸í•˜ì„¸ìš”", type=["pdf"])
    
    # íŒŒì¼ì´ ì˜¬ë¼ì˜¤ë©´ ì‹¤í–‰ë˜ëŠ” ë¶€ë¶„
    if uploaded_file is not None:
        try:
            # 1. PDF íŒŒì¼ ì½ê¸°
            reader = PyPDF2.PdfReader(uploaded_file)
            pdf_text = ""
            
            # 2. ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for page in reader.pages:
                pdf_text += page.extract_text()
            
            # 3. ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì±—ë´‡ì—ê²Œ 'ì°¸ê³  ìë£Œ'ë¡œ ë„˜ê²¨ì£¼ê¸° ìœ„í•´ ì„¸ì…˜ì— ì €ì¥
            # (ì´ë¯¸ ì €ì¥ëœ ì  ì—†ìœ¼ë©´ ì €ì¥)
            if "pdf_context" not in st.session_state or st.session_state.pdf_context != pdf_text:
                st.session_state.pdf_context = pdf_text
                # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— PDF ë‚´ìš© ì¶”ê°€ (ê°•ì œë¡œ ì£¼ì…!)
                st.session_state.messages.append(
                    {"role": "system", "content": f"ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œ ë‚´ìš©ì´ì•¼. ì§ˆë¬¸ì— ë‹µí•  ë•Œ ì´ ë‚´ìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•´:\n\n{pdf_text}"}
                )
                st.success("íŒê²°ë¬¸ ë‚´ìš©ì„ ë‹¤ ì½ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸í•˜ì„¸ìš”.")
                
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì—ëŸ¬ê°€ ë‚¬ì–´ìš”: {e}")

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# (ì‹¤ì œ ê°’ì€ .env íŒŒì¼ì´ë‚˜ ì—¬ê¸°ì— ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”)
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# 3. ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™” - ì´ê²Œ ì—†ìœ¼ë©´ ìƒˆë¡œê³ ì¹¨ ë•Œë§ˆë‹¤ ëŒ€í™”ê°€ ë‚ ì•„ê°‘ë‹ˆë‹¤!
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content" : 
    "ë„ˆëŠ” 30ë…„ ê²½ë ¥ì˜ ë¯¼ì‚¬ì†Œì†¡ë²• ì „ë¬¸ ê°•ì‚¬ì•¼. ë¹„ì „ê³µìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ë²•ë¥  ìš©ì–´ë¥¼ ì‰¬ìš´ ë¹„ìœ ë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ê³ , íŒë¡€ ë²ˆí˜¸ë¥¼ ì£¼ë©´ í•µì‹¬ ìŸì ê³¼ ê²°ë¡ ì„ ëª…í™•íˆ ìš”ì•½í•´ì¤˜. ë§íˆ¬ëŠ” ì •ì¤‘í•˜ì§€ë§Œ ì¹œì ˆí•˜ê²Œ í•´ì¤˜."}]

# 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) AI ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì•„ë‹˜, ë‹¨ìˆœ í˜¸ì¶œ ì˜ˆì‹œ)
    with st.chat_message("assistant"):
        response = client.chat.completions.create(
        model= "gpt-4o-mini", # .envì— ìˆëŠ” ë°°í¬ ì´ë¦„
        messages=st.session_state.messages,
        extra_body={
            "data_sources": [
                {
                    "type": "azure_search",
                    "parameters": {
                        "endpoint": search_endpoint,
                        "index_name": search_index,
                        "authentication": {
                            "type": "api_key",
                            "key": search_key
                        },
                        # ì—¬ê¸° ì¤‘ìš”! ê²€ìƒ‰ ì„¤ì •ì„ ë„¤ ìƒí™©ì— ë§ê²Œ ì¡°ì ˆ
                        "in_scope": True, # Trueë©´ ê²€ìƒ‰ ê²°ê³¼ ë‚´ì—ì„œë§Œ ë‹µë³€ (ì—„ê²© ëª¨ë“œ)
                        "top_n_documents": 5, # ì°¸ê³ í•  ë¬¸ì„œ ê°œìˆ˜
                        "query_type": "simple" # ë˜ëŠ” "vector", "semantic" ë“± ì„¤ì •ì— ë§ê²Œ
                    }
                }
            ]
        }
    )
        answer = response.choices[0].message.content
        st.markdown(answer)

    # (3) AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": answer})
